{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Proiect_ML.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyN7WSOC7oi/AE3nROZ4vk15",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sorinNgit/Machine-Learning-Image-Classification/blob/main/Proiect_ML.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ad286CRIV6g"
      },
      "source": [
        "!unzip ai-unibuc-24-22-2021.zip\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qE1eBU7fBhRd",
        "outputId": "bb90fc6e-e9e6-48d9-b301-0b06d374c558"
      },
      "source": [
        "from pathlib import Path\n",
        "import numpy as np\n",
        "from matplotlib.image import imread\n",
        "import cv2 as cv\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn import svm\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "out = open(\"output.txt\", \"w\")\n",
        "\n",
        "def normalize_img(path):\n",
        "    img = cv.imread(path, cv.IMREAD_GRAYSCALE)\n",
        "    normalizedImg = np.zeros((32, 32))\n",
        "    normalizedImg = cv.normalize(img, normalizedImg, 0, 255, cv.NORM_MINMAX)\n",
        "\n",
        "    #return normalizedImg.flatten()\n",
        "    return normalizedImg\n",
        "\n",
        "def load_data(data_dir, file_names):\n",
        "    return [normalize_img(data_dir + \"/\" + name) for name in file_names]\n",
        "\n",
        "def read_labels(path, column_names=['id', 'label']):\n",
        "    return pd.read_csv(path, names=column_names)\n",
        "\n",
        "def load_labeled_data(data_dir, df):\n",
        "    data = load_data(data_dir, df.id)\n",
        "    labels = list(df.label)\n",
        "    return data, labels\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "DATA_DIR = ''\n",
        "def load_training_dataset():\n",
        "    print(\"Loading provided training dataset\")\n",
        "    train_df = read_labels(DATA_DIR + 'train.txt')\n",
        "    return load_labeled_data(DATA_DIR + 'train', train_df)\n",
        "\n",
        "def load_validation_dataset():\n",
        "    print(\"Loading provided validation dataset\")\n",
        "    validation_df = read_labels(DATA_DIR + 'validation.txt')\n",
        "    return load_labeled_data(DATA_DIR + 'validation', validation_df)\n",
        "\n",
        "def load_labeled_dataset():\n",
        "    train_data, train_labels = load_training_dataset()\n",
        "    validation_data, validation_labels = load_validation_dataset()\n",
        "\n",
        "    # Merge all labeled data into a single array\n",
        "    data = np.stack(train_data + validation_data)\n",
        "    labels = np.stack(train_labels + validation_labels)\n",
        "\n",
        "    print(\"Loaded\", len(data), \"labeled samples\")\n",
        "\n",
        "    return data, labels\n",
        "\n",
        "def load_test_dataset():\n",
        "    print(\"Loading unlabeled dataset\")\n",
        "\n",
        "    test_df = read_labels(DATA_DIR + 'test.txt', column_names=['name'])\n",
        "\n",
        "    test_df = test_df.set_index('name')\n",
        "\n",
        "    return test_df, load_data(DATA_DIR + 'test', test_df.index)\n",
        "\n",
        "\n",
        "train_data, train_labels = load_training_dataset()\n",
        "validation_data, validation_labels = load_validation_dataset()\n",
        "test_df,test_data = load_test_dataset()\n",
        "#data, labels = load_labeled_dataset()\n",
        "out.write(\"id,label\\n\")\n",
        "\n",
        "#clf = svm.SVC(C=9, kernel='rbf')\n",
        "#clf.fit(train_data, train_labels)\n",
        "#validation_predict = clf.predict(validation_data)\n",
        "#accuracy = accuracy_score(validation_labels, validation_predict)\n",
        "#print(accuracy)\n",
        "\n",
        "#for i,j in zip(test_df.index, test_predict):\n",
        "#    out.write(str(i) + \",\" + str(j) + '\\n')\n",
        "\n",
        "#out.close()\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading provided training dataset\n",
            "Loading provided validation dataset\n",
            "Loading unlabeled dataset\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JGQyia3JDIMn",
        "outputId": "5d3b587c-f0e6-4ce4-8778-6ab3e7c8127d"
      },
      "source": [
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.layers import Activation, Dropout, Flatten, Dense\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.layers import BatchNormalization, SeparableConv2D\n",
        "from keras.utils import normalize, to_categorical\n",
        "from keras.losses import SparseCategoricalCrossentropy\n",
        "train_normalized_data = np.array(train_data).reshape(len(train_data),32,32,1).astype('float32')\n",
        "train_normalized_data /=255.0\n",
        "train_normalized_data = np.array(train_labels)\n",
        "\n",
        "\n",
        "X = np.array(train_data).reshape(len(train_data),32,32,1)\n",
        "y = np.array(train_labels)\n",
        "X = X.astype('float32')\n",
        "X /= 255.0\n",
        "\n",
        "\n",
        "Vimgs = np.array(validation_data).reshape(len(validation_data),32,32,1)\n",
        "Vlbl = np.array(validation_labels)\n",
        "Vimgs = Vimgs.astype('float32')\n",
        "Vimgs /= 255.0\n",
        "\n",
        "Timgs = np.array(test_data).reshape(len(test_data),32,32,1)\n",
        "Timgs = Timgs.astype('float32')\n",
        "Timgs /= 255.0\n",
        "\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(32,(3,3),activation = \"relu\", input_shape = (32,32,1), padding = 'valid'))\n",
        "model.add(BatchNormalization(axis = -1))\n",
        "model.add(SeparableConv2D(64, (3,3), activation = 'relu' , padding = 'valid'))\n",
        "model.add(BatchNormalization(axis = -1))\n",
        "model.add(MaxPooling2D(pool_size = (2,2)))\n",
        "model.add(SeparableConv2D(64, (3,3), activation = 'relu' , padding = 'valid'))\n",
        "model.add(BatchNormalization(axis = -1))\n",
        "model.add(Conv2D(32,(3,3), activation = 'relu', padding = 'valid'))\n",
        "model.add(BatchNormalization(axis = -1))\n",
        "model.add(MaxPooling2D(pool_size = (2,2)))\n",
        "model.add(Dropout(0.6))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(512, activation = \"relu\"))\n",
        "model.add(Dense(9, activation = \"softmax\"))\n",
        "\n",
        "\n",
        "model.compile(optimizer=\"adam\", loss=SparseCategoricalCrossentropy(), metrics=[\"accuracy\"])\n",
        "#model.compile(optimizer=keras.optimizers.Adam(learning_rate=3e-3), loss=keras.losses.SparseCategoricalCrossentropy(), metrics='accuracy')\n",
        "\n",
        "#train_datagen = ImageDataGenerator(\n",
        " #   rotation_angle = 45,\n",
        "  #  width_shift_range = 0.2,\n",
        "   # zoom_range = 0.2,\n",
        "    #horizontal_flip = True)\n",
        "#train_datagen.fit(train_data)\n",
        "\n",
        "#train_generator = train_datagen.flow(\n",
        " #   train_data,\n",
        "  #  train_labels,\n",
        "   # batch_size = 32\n",
        "#)\n",
        "\n",
        "model.fit(X, y, epochs = 50, validation_data = (Vimgs, Vlbl))\n",
        "\n",
        "\n",
        "#history = model.fit_generator(train_generator, epochs = 10, steps_per_epoch = 500, validation_data = (???),verbose = 1)\n",
        "\n",
        "model.evaluate(Vimgs, Vlbl)\n",
        "\n",
        "predicted_labels = model.predict_classes(Timgs)\n",
        "\n",
        "out = open(\"output.txt\", \"w\")\n",
        "out.write(\"id,label\\n\")\n",
        "\n",
        "for i,j in zip(test_df.index, predicted_labels):\n",
        "    out.write(str(i) + \",\" + str(j) + '\\n')\n",
        "\n",
        "\n",
        "out.close()\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "938/938 [==============================] - 8s 8ms/step - loss: 1.5225 - accuracy: 0.5376 - val_loss: 0.6713 - val_accuracy: 0.7782\n",
            "Epoch 2/50\n",
            "938/938 [==============================] - 7s 8ms/step - loss: 0.7866 - accuracy: 0.7175 - val_loss: 0.5931 - val_accuracy: 0.7938\n",
            "Epoch 3/50\n",
            "938/938 [==============================] - 7s 8ms/step - loss: 0.6783 - accuracy: 0.7536 - val_loss: 0.5242 - val_accuracy: 0.8220\n",
            "Epoch 4/50\n",
            "938/938 [==============================] - 7s 8ms/step - loss: 0.6180 - accuracy: 0.7773 - val_loss: 0.5109 - val_accuracy: 0.8206\n",
            "Epoch 5/50\n",
            "938/938 [==============================] - 7s 8ms/step - loss: 0.5720 - accuracy: 0.7929 - val_loss: 0.4808 - val_accuracy: 0.8284\n",
            "Epoch 6/50\n",
            "938/938 [==============================] - 8s 8ms/step - loss: 0.5442 - accuracy: 0.8047 - val_loss: 0.4360 - val_accuracy: 0.8430\n",
            "Epoch 7/50\n",
            "938/938 [==============================] - 7s 8ms/step - loss: 0.5124 - accuracy: 0.8174 - val_loss: 0.4481 - val_accuracy: 0.8422\n",
            "Epoch 8/50\n",
            "938/938 [==============================] - 7s 8ms/step - loss: 0.4845 - accuracy: 0.8270 - val_loss: 0.4608 - val_accuracy: 0.8380\n",
            "Epoch 9/50\n",
            "938/938 [==============================] - 7s 8ms/step - loss: 0.4559 - accuracy: 0.8367 - val_loss: 0.4100 - val_accuracy: 0.8538\n",
            "Epoch 10/50\n",
            "938/938 [==============================] - 7s 8ms/step - loss: 0.4390 - accuracy: 0.8406 - val_loss: 0.4097 - val_accuracy: 0.8546\n",
            "Epoch 11/50\n",
            "938/938 [==============================] - 8s 8ms/step - loss: 0.4243 - accuracy: 0.8472 - val_loss: 0.3836 - val_accuracy: 0.8592\n",
            "Epoch 12/50\n",
            "938/938 [==============================] - 7s 8ms/step - loss: 0.3973 - accuracy: 0.8558 - val_loss: 0.4057 - val_accuracy: 0.8572\n",
            "Epoch 13/50\n",
            "938/938 [==============================] - 7s 8ms/step - loss: 0.3934 - accuracy: 0.8619 - val_loss: 0.3709 - val_accuracy: 0.8666\n",
            "Epoch 14/50\n",
            "938/938 [==============================] - 7s 8ms/step - loss: 0.3713 - accuracy: 0.8632 - val_loss: 0.4846 - val_accuracy: 0.8272\n",
            "Epoch 15/50\n",
            "938/938 [==============================] - 7s 8ms/step - loss: 0.3676 - accuracy: 0.8695 - val_loss: 0.3590 - val_accuracy: 0.8728\n",
            "Epoch 16/50\n",
            "938/938 [==============================] - 8s 8ms/step - loss: 0.3445 - accuracy: 0.8787 - val_loss: 0.3544 - val_accuracy: 0.8698\n",
            "Epoch 17/50\n",
            "938/938 [==============================] - 8s 8ms/step - loss: 0.3374 - accuracy: 0.8798 - val_loss: 0.3508 - val_accuracy: 0.8764\n",
            "Epoch 18/50\n",
            "938/938 [==============================] - 7s 8ms/step - loss: 0.3338 - accuracy: 0.8806 - val_loss: 0.3621 - val_accuracy: 0.8670\n",
            "Epoch 19/50\n",
            "938/938 [==============================] - 7s 8ms/step - loss: 0.3203 - accuracy: 0.8835 - val_loss: 0.3404 - val_accuracy: 0.8798\n",
            "Epoch 20/50\n",
            "938/938 [==============================] - 7s 8ms/step - loss: 0.3204 - accuracy: 0.8854 - val_loss: 0.3602 - val_accuracy: 0.8666\n",
            "Epoch 21/50\n",
            "938/938 [==============================] - 7s 8ms/step - loss: 0.3058 - accuracy: 0.8905 - val_loss: 0.3760 - val_accuracy: 0.8706\n",
            "Epoch 22/50\n",
            "938/938 [==============================] - 8s 8ms/step - loss: 0.3053 - accuracy: 0.8923 - val_loss: 0.3309 - val_accuracy: 0.8792\n",
            "Epoch 23/50\n",
            "938/938 [==============================] - 7s 8ms/step - loss: 0.2971 - accuracy: 0.8942 - val_loss: 0.3527 - val_accuracy: 0.8690\n",
            "Epoch 24/50\n",
            "938/938 [==============================] - 7s 8ms/step - loss: 0.2756 - accuracy: 0.8980 - val_loss: 0.3797 - val_accuracy: 0.8646\n",
            "Epoch 25/50\n",
            "938/938 [==============================] - 8s 8ms/step - loss: 0.2776 - accuracy: 0.8991 - val_loss: 0.3309 - val_accuracy: 0.8742\n",
            "Epoch 26/50\n",
            "938/938 [==============================] - 8s 8ms/step - loss: 0.2753 - accuracy: 0.9007 - val_loss: 0.3377 - val_accuracy: 0.8756\n",
            "Epoch 27/50\n",
            "938/938 [==============================] - 8s 8ms/step - loss: 0.2674 - accuracy: 0.9031 - val_loss: 0.3331 - val_accuracy: 0.8756\n",
            "Epoch 28/50\n",
            "938/938 [==============================] - 7s 8ms/step - loss: 0.2590 - accuracy: 0.9081 - val_loss: 0.3243 - val_accuracy: 0.8788\n",
            "Epoch 29/50\n",
            "938/938 [==============================] - 7s 8ms/step - loss: 0.2527 - accuracy: 0.9084 - val_loss: 0.3353 - val_accuracy: 0.8776\n",
            "Epoch 30/50\n",
            "938/938 [==============================] - 8s 8ms/step - loss: 0.2497 - accuracy: 0.9096 - val_loss: 0.3359 - val_accuracy: 0.8730\n",
            "Epoch 31/50\n",
            "938/938 [==============================] - 7s 8ms/step - loss: 0.2498 - accuracy: 0.9120 - val_loss: 0.3358 - val_accuracy: 0.8780\n",
            "Epoch 32/50\n",
            "938/938 [==============================] - 7s 8ms/step - loss: 0.2473 - accuracy: 0.9125 - val_loss: 0.3230 - val_accuracy: 0.8832\n",
            "Epoch 33/50\n",
            "938/938 [==============================] - 8s 8ms/step - loss: 0.2313 - accuracy: 0.9162 - val_loss: 0.3228 - val_accuracy: 0.8836\n",
            "Epoch 34/50\n",
            "938/938 [==============================] - 7s 8ms/step - loss: 0.2336 - accuracy: 0.9153 - val_loss: 0.3311 - val_accuracy: 0.8770\n",
            "Epoch 35/50\n",
            "938/938 [==============================] - 7s 8ms/step - loss: 0.2305 - accuracy: 0.9177 - val_loss: 0.3275 - val_accuracy: 0.8802\n",
            "Epoch 36/50\n",
            "938/938 [==============================] - 8s 8ms/step - loss: 0.2218 - accuracy: 0.9193 - val_loss: 0.3239 - val_accuracy: 0.8812\n",
            "Epoch 37/50\n",
            "938/938 [==============================] - 7s 8ms/step - loss: 0.2260 - accuracy: 0.9175 - val_loss: 0.3270 - val_accuracy: 0.8814\n",
            "Epoch 38/50\n",
            "938/938 [==============================] - 7s 8ms/step - loss: 0.2202 - accuracy: 0.9215 - val_loss: 0.3292 - val_accuracy: 0.8808\n",
            "Epoch 39/50\n",
            "938/938 [==============================] - 7s 8ms/step - loss: 0.2159 - accuracy: 0.9211 - val_loss: 0.3343 - val_accuracy: 0.8786\n",
            "Epoch 40/50\n",
            "938/938 [==============================] - 8s 8ms/step - loss: 0.2119 - accuracy: 0.9234 - val_loss: 0.3292 - val_accuracy: 0.8840\n",
            "Epoch 41/50\n",
            "938/938 [==============================] - 8s 8ms/step - loss: 0.2112 - accuracy: 0.9258 - val_loss: 0.3368 - val_accuracy: 0.8764\n",
            "Epoch 42/50\n",
            "938/938 [==============================] - 7s 8ms/step - loss: 0.2159 - accuracy: 0.9211 - val_loss: 0.3277 - val_accuracy: 0.8816\n",
            "Epoch 43/50\n",
            "938/938 [==============================] - 7s 8ms/step - loss: 0.2048 - accuracy: 0.9264 - val_loss: 0.3220 - val_accuracy: 0.8834\n",
            "Epoch 44/50\n",
            "938/938 [==============================] - 7s 8ms/step - loss: 0.2063 - accuracy: 0.9240 - val_loss: 0.3326 - val_accuracy: 0.8776\n",
            "Epoch 45/50\n",
            "938/938 [==============================] - 7s 8ms/step - loss: 0.2031 - accuracy: 0.9293 - val_loss: 0.3281 - val_accuracy: 0.8776\n",
            "Epoch 46/50\n",
            "938/938 [==============================] - 7s 8ms/step - loss: 0.2029 - accuracy: 0.9269 - val_loss: 0.3470 - val_accuracy: 0.8764\n",
            "Epoch 47/50\n",
            "938/938 [==============================] - 7s 8ms/step - loss: 0.1997 - accuracy: 0.9281 - val_loss: 0.3370 - val_accuracy: 0.8778\n",
            "Epoch 48/50\n",
            "938/938 [==============================] - 8s 8ms/step - loss: 0.1926 - accuracy: 0.9309 - val_loss: 0.3884 - val_accuracy: 0.8604\n",
            "Epoch 49/50\n",
            "938/938 [==============================] - 8s 8ms/step - loss: 0.1962 - accuracy: 0.9267 - val_loss: 0.3505 - val_accuracy: 0.8784\n",
            "Epoch 50/50\n",
            "938/938 [==============================] - 7s 8ms/step - loss: 0.1875 - accuracy: 0.9348 - val_loss: 0.3247 - val_accuracy: 0.8802\n",
            "157/157 [==============================] - 0s 2ms/step - loss: 0.3247 - accuracy: 0.8802\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}